{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the UCI Machine Learning repository and download the Spambase dataset. Make sure you read the documentation for the data. This explains what the attributes are in the data file. Load in the data file, doing any cleaning necessary to get usable data.\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.DOCUMENTATION\n",
    "\n",
    "Subsample the data set so 60% is training data and 40% is test data. You can subsample however you like, including splitting the original file. Just make sure that you have a representative data set. (The original is about 60% not-spam and 40% spam.)\n",
    "\n",
    "Then, write code to classify the data into spam and not-spam, training with your training data and testing on your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_1</th>\n",
       "      <th>word_freq_2</th>\n",
       "      <th>word_freq_3</th>\n",
       "      <th>word_freq_4</th>\n",
       "      <th>word_freq_5</th>\n",
       "      <th>word_freq_6</th>\n",
       "      <th>word_freq_7</th>\n",
       "      <th>word_freq_8</th>\n",
       "      <th>word_freq_9</th>\n",
       "      <th>word_freq_10</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_1</th>\n",
       "      <th>char_freq_2</th>\n",
       "      <th>char_freq_3</th>\n",
       "      <th>char_freq_4</th>\n",
       "      <th>char_freq_5</th>\n",
       "      <th>char_freq_6</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_1  word_freq_2  word_freq_3  word_freq_4  word_freq_5  \\\n",
       "0         0.00         0.64         0.64          0.0         0.32   \n",
       "1         0.21         0.28         0.50          0.0         0.14   \n",
       "2         0.06         0.00         0.71          0.0         1.23   \n",
       "3         0.00         0.00         0.00          0.0         0.63   \n",
       "4         0.00         0.00         0.00          0.0         0.63   \n",
       "\n",
       "   word_freq_6  word_freq_7  word_freq_8  word_freq_9  word_freq_10  ...   \\\n",
       "0         0.00         0.00         0.00         0.00          0.00  ...    \n",
       "1         0.28         0.21         0.07         0.00          0.94  ...    \n",
       "2         0.19         0.19         0.12         0.64          0.25  ...    \n",
       "3         0.00         0.31         0.63         0.31          0.63  ...    \n",
       "4         0.00         0.31         0.63         0.31          0.63  ...    \n",
       "\n",
       "   char_freq_1  char_freq_2  char_freq_3  char_freq_4  char_freq_5  \\\n",
       "0         0.00        0.000          0.0        0.778        0.000   \n",
       "1         0.00        0.132          0.0        0.372        0.180   \n",
       "2         0.01        0.143          0.0        0.276        0.184   \n",
       "3         0.00        0.137          0.0        0.137        0.000   \n",
       "4         0.00        0.135          0.0        0.135        0.000   \n",
       "\n",
       "   char_freq_6  capital_run_length_average  capital_run_length_longest  \\\n",
       "0        0.000                       3.756                          61   \n",
       "1        0.048                       5.114                         101   \n",
       "2        0.010                       9.821                         485   \n",
       "3        0.000                       3.537                          40   \n",
       "4        0.000                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(url)\n",
    "names = (['word_freq_' + str(i+1) for i in range(48)] \n",
    "         + ['char_freq_' + str(j+1) for j in range(6)] \n",
    "         + ['capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'spam'])\n",
    "spam = pd.read_csv(StringIO(r.text), names=names)\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsample the data set so 60% is training data and 40% is test data. You can subsample however you like, including splitting the original file. Just make sure that you have a representative data set. (The original is about 60% not-spam and 40% spam.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39978272677892451"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(spam.drop('spam', axis=1),\n",
    "                                                    spam['spam'],\n",
    "                                                    test_size = 0.4, random_state=6)\n",
    "sum(test_y) / len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, write code to classify the data into spam and not-spam, training with your training data and testing on your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB().fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40901683867463334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_x)\n",
    "sum(predictions) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_rate = accuracy_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From UCI Data:\n",
    "\n",
    "*~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\"Marking good mail as spam\"\n",
    "test_results = pd.DataFrame({'test_y': test_y, 'predictions': predictions})\n",
    "test_results['False Positive'] = test_results['predictions'] > test_results['test_y']\n",
    "test_results['False Negative'] = test_results['predictions'] < test_results['test_y']\n",
    "test_results['Correct'] = test_results['predictions'] == test_results['test_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Accuracy: 81.04%\n",
      "False Positive: 9.94%\n",
      "False Negative: 9.02%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "false_pos_rate = test_results['False Positive'].sum() / len(test_results)\n",
    "false_neg_rate = test_results['False Negative'].sum() / len(test_results)\n",
    "print(\"\"\"\n",
    "Results:\n",
    "Accuracy: {:.2f}%\n",
    "False Positive: {:.2f}%\n",
    "False Negative: {:.2f}%\n",
    "\"\"\".format(accuracy_rate * 100, false_pos_rate * 100, false_neg_rate * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Mode\n",
    "\n",
    "In addition to the normal mode requirements, try reducing or changing your features in order to get better results.\n",
    "\n",
    "Find another source of spam/not-spam data, break it down into features, and perform the same exercise as above. How well does your algorithm perform on the new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combo_accs = []\n",
    "# combo_names = []\n",
    "# for i in range(1,58):\n",
    "#     for combo in combinations(train_x.columns, i):\n",
    "#         combo = list(combo)\n",
    "#         test_x_combo = test_x[combo]\n",
    "#         train_x_combo = train_x[combo]\n",
    "#         model_combo = MultinomialNB().fit(train_x_combo, train_y)\n",
    "#         pred_combo = model_combo.predict(test_x_combo)\n",
    "#         pred_acc = accuracy_score(test_y, pred_combo)\n",
    "        \n",
    "#         combo_accs.append(pred_acc)\n",
    "#         combo_names.append(combo)\n",
    "\n",
    "# test_comb_accs = pd.DataFrame(combo_names, combo_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried getting all combos above, but this was taking longer than I had patience for...\n",
    "So now I'll investigate looking only at words, or words and characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_x_words = test_x[test_x.columns[:48]]\n",
    "train_x_words = train_x[train_x.columns[:48]]\n",
    "\n",
    "model_words = MultinomialNB().fit(train_x_words, train_y)\n",
    "pred_words = model_words.predict(test_x_words)\n",
    "pred_words_acc = accuracy_score(test_y, pred_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86800651819663222"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_words_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87506789788158612"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_words_chars = test_x[test_x.columns[:54]]\n",
    "train_x_words_chars = train_x[train_x.columns[:54]]\n",
    "\n",
    "model_words_chars = MultinomialNB().fit(train_x_words_chars, train_y)\n",
    "pred_words_chars = model_words_chars.predict(test_x_words_chars)\n",
    "pred_words_chars_acc = accuracy_score(test_y, pred_words_chars)\n",
    "pred_words_chars_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a much higher accuracy score of 87.5% when we exclude the three capital run length metrics, and look only at words and characters.\n",
    "\n",
    "Now, to check and see what happens if we add each of the capital run metrics back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87235198261814229"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_words_chars = test_x[test_x.columns[:55]]\n",
    "train_x_words_chars = train_x[train_x.columns[:55]]\n",
    "\n",
    "model_words_chars = MultinomialNB().fit(train_x_words_chars, train_y)\n",
    "pred_words_chars = model_words_chars.predict(test_x_words_chars)\n",
    "pred_words_chars_acc = accuracy_score(test_y, pred_words_chars)\n",
    "pred_words_chars_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8359587180879956"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_x.columns[:54]) + ['capital_run_length_longest']\n",
    "test_x_words_chars = test_x[list(test_x.columns[:54]) + ['capital_run_length_longest']]\n",
    "train_x_words_chars = train_x[list(train_x.columns[:54]) + ['capital_run_length_longest']]\n",
    "\n",
    "model_words_chars = MultinomialNB().fit(train_x_words_chars, train_y)\n",
    "pred_words_chars = model_words_chars.predict(test_x_words_chars)\n",
    "pred_words_chars_acc = accuracy_score(test_y, pred_words_chars)\n",
    "pred_words_chars_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85279739272134714"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_x.columns[:54]) + ['capital_run_length_total']\n",
    "test_x_words_chars = test_x[list(test_x.columns[:54]) + ['capital_run_length_total']]\n",
    "train_x_words_chars = train_x[list(train_x.columns[:54]) + ['capital_run_length_total']]\n",
    "\n",
    "model_words_chars = MultinomialNB().fit(train_x_words_chars, train_y)\n",
    "pred_words_chars = model_words_chars.predict(test_x_words_chars)\n",
    "pred_words_chars_acc = accuracy_score(test_y, pred_words_chars)\n",
    "pred_words_chars_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As each of these lowered the accuracy score, we will assume that excluding the three capital run length features will lead to a more accurate model.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
